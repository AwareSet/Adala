{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c119c3",
   "metadata": {},
   "source": [
    "# ADALA Quickstart\n",
    "\n",
    "In this notebook, we are going to run through some of the common tasks for creating data labeling agents with ADALA. In this example, we're going to create a data labeling agent for a text classification task - labeling our text samples as either \"Subjective or \"Objective\" statements. \n",
    "\n",
    "This agent will be LLM-based, so we will use [OpenAI's API](https://platform.openai.com/). You will to generate an API key and set it as an environment variable as follows: \n",
    "\n",
    "```\n",
    "export OPENAI_API_KEY=your_openai_api_key\n",
    "```\n",
    "\n",
    "Now, let's begin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c19afc",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "First, let's use a dataset of product reviews stored in pandas dataframe. This will help us manage our data as we add more attributes, like predictions and labels for subjectivity and objectivity over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5b37a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The mic is great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will order from them again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not loud enough and doesn't turn on like it sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The phone doesn't seem to accept anything exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All three broke within two months of use.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                  The mic is great.\n",
       "1                        Will order from them again!\n",
       "2  Not loud enough and doesn't turn on like it sh...\n",
       "3  The phone doesn't seem to accept anything exce...\n",
       "4          All three broke within two months of use."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts = [\n",
    "    \"The mic is great.\",\n",
    "    \"Will order from them again!\",\n",
    "    \"Not loud enough and doesn't turn on like it should.\",\n",
    "    \"The phone doesn't seem to accept anything except CBR mp3s\",\n",
    "    \"All three broke within two months of use.\"\n",
    "]\n",
    "df = pd.DataFrame(texts, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc201b3",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "Agent's abilities are defined as **\"Skills\"**. Each agent can possess many different skills. In our case, this agent only has one labeling skill, to produce a classification of Subjective or Objective for a given piece of text. \n",
    "\n",
    "To define this skill, we will leverage an LLM, passing it instructions and the set of labeles we expect to receive back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1310fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(environment=Environment(dataset=DataFrameDataset(inputs=DatasetInputSchema(input_specs={'text': {}}), df=                                                text  ground_truth\n",
       "0                                  The mic is great.           NaN\n",
       "1                        Will order from them again!           NaN\n",
       "2  Not loud enough and doesn't turn on like it sh...           NaN\n",
       "3  The phone doesn't seem to accept anything exce...           NaN\n",
       "4          All three broke within two months of use.           NaN, ground_truth_column='ground_truth')), skills=LinearSkillSet(skills={'skill_0': ClassificationSkill(name='subjectivity_detection', instructions='Classify a product review as either expressing \"Subjective\" or \"Objective\" statements.', description='Understanding subjective and objective statements from text.', input_template='Input: {{{{input}}}}', output_template=\"Output: {{{{select 'predictions' options=labels logprobs='score'}}}}\", validation_fields=['predictions'], labels=['Subjective', 'Objective'], prediction_field='predictions')}, skill_sequence=['skill_0']), memory=None, runtimes={'openai': LLMRuntime(verbose=False, llm_runtime_type=<LLMRuntimeModelType.OpenAI: 'OpenAI'>, llm_params={'model': 'gpt-3.5-turbo-instruct'}), 'openai-gpt4': LLMRuntime(verbose=False, llm_runtime_type=<LLMRuntimeModelType.OpenAI: 'OpenAI'>, llm_params={'model': 'gpt-4'})}, default_runtime='openai')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adala.agents import Agent\n",
    "from adala.datasets import DataFrameDataset\n",
    "from adala.skills import ClassificationSkill\n",
    "\n",
    "agent = Agent(\n",
    "    # connect to a dataset\n",
    "    environment=DataFrameDataset(df=df, inputs=['text']),\n",
    "    \n",
    "    # define the agent's labeling skill\n",
    "    skills=ClassificationSkill(\n",
    "        name='subjectivity_detection',\n",
    "        description='Understanding subjective and objective statements from text.',\n",
    "        instructions='Classify a product review as either expressing \"Subjective\" or \"Objective\" statements.',\n",
    "        labels=['Subjective', 'Objective']\n",
    "    )\n",
    ")\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340dde8",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "We will now apply the skill to each of the tasks in our dataframe by running the agent. Our result will be a dataframe that we'll combine with our original data to view together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666c8d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 109, in run\n",
      "    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 559, in visit\n",
      "    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 186, in visit\n",
      "    out = await self.visit(tree, variable_stack)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 559, in visit\n",
      "    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 266, in visit\n",
      "    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 266, in <listcomp>\n",
      "    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nik/PycharmProjects/guidance/guidance/_program_executor.py\", line 413, in visit\n",
      "    raise KeyError(\"Command/variable '\"+command_name+\"' not found! Please pass it when calling the program (or set a default value for it when creating the program).\")\n",
      "KeyError: \"Command/variable 'input' not found! Please pass it when calling the program (or set a default value for it when creating the program).\"\n",
      "\n",
      "Error in program:  \"Command/variable 'input' not found! Please pass it when calling the program (or set a default value for it when creating the program).\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mapply_skills()\n\u001B[1;32m      2\u001B[0m pd\u001B[38;5;241m.\u001B[39mconcat((df, run_results\u001B[38;5;241m.\u001B[39mexperience\u001B[38;5;241m.\u001B[39mpredictions), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/agents/base.py:77\u001B[0m, in \u001B[0;36mAgent.apply_skills\u001B[0;34m(self, runtime)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_skills\u001B[39m(\u001B[38;5;28mself\u001B[39m, runtime: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ShortTermMemory:\n\u001B[0;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskills\u001B[38;5;241m.\u001B[39mapply(dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menvironment\u001B[38;5;241m.\u001B[39mdataset, runtime\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_runtime(runtime\u001B[38;5;241m=\u001B[39mruntime))\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/skills/skillset.py:62\u001B[0m, in \u001B[0;36mLinearSkillSet.apply\u001B[0;34m(self, dataset, runtime, experience)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m skill_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskill_sequence:\n\u001B[1;32m     61\u001B[0m     skill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskills[skill_name]\n\u001B[0;32m---> 62\u001B[0m     experience \u001B[38;5;241m=\u001B[39m skill\u001B[38;5;241m.\u001B[39mapply(dataset, runtime, experience)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m experience\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/skills/base.py:142\u001B[0m, in \u001B[0;36mLLMSkill.apply\u001B[0;34m(self, dataset, runtime, experience)\u001B[0m\n\u001B[1;32m    139\u001B[0m predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataset\u001B[38;5;241m.\u001B[39mbatch_iterator():\n\u001B[0;32m--> 142\u001B[0m     runtime_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(batch, runtime, dataset)\n\u001B[1;32m    143\u001B[0m     predictions\u001B[38;5;241m.\u001B[39mappend(runtime_predictions)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m predictions:\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/skills/base.py:83\u001B[0m, in \u001B[0;36mBaseSkill.__call__\u001B[0;34m(self, input, runtime, dataset)\u001B[0m\n\u001B[1;32m     79\u001B[0m system_fields \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_template\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_template\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minstructions\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_fields\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[1;32m     81\u001B[0m extra_fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_dump(exclude\u001B[38;5;241m=\u001B[39msystem_fields)\n\u001B[0;32m---> 83\u001B[0m runtime_predictions \u001B[38;5;241m=\u001B[39m runtime\u001B[38;5;241m.\u001B[39mprocess_batch(\n\u001B[1;32m     84\u001B[0m     batch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m     85\u001B[0m     input_template\u001B[38;5;241m=\u001B[39minput_template,\n\u001B[1;32m     86\u001B[0m     output_template\u001B[38;5;241m=\u001B[39moutput_template,\n\u001B[1;32m     87\u001B[0m     instructions\u001B[38;5;241m=\u001B[39minstructions,\n\u001B[1;32m     88\u001B[0m     extra_fields\u001B[38;5;241m=\u001B[39mextra_fields\n\u001B[1;32m     89\u001B[0m )\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m runtime_predictions\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/runtimes/base.py:164\u001B[0m, in \u001B[0;36mLLMRuntime.process_batch\u001B[0;34m(self, batch, input_template, output_template, instructions, extra_fields)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;66;03m# TODO: it's not efficient way to initialize the program here - should be done once\u001B[39;00m\n\u001B[1;32m    159\u001B[0m extra_fields\u001B[38;5;241m.\u001B[39mupdate({\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_program\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_input_program(input_template),\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_program\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_output_program(output_template),\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minstructions_program\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_instructions_program(instructions),\n\u001B[1;32m    163\u001B[0m })\n\u001B[0;32m--> 164\u001B[0m output \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mprogress_apply(\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_record,\n\u001B[1;32m    166\u001B[0m     axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    167\u001B[0m     result_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexpand\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    168\u001B[0m     program\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_program,\n\u001B[1;32m    169\u001B[0m     outputs\u001B[38;5;241m=\u001B[39moutputs,\n\u001B[1;32m    170\u001B[0m     extra_fields\u001B[38;5;241m=\u001B[39mextra_fields\n\u001B[1;32m    171\u001B[0m )\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/tqdm/std.py:920\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[0;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    917\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 920\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(df, df_function)(wrapper, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    922\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/pandas/core/frame.py:9423\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   9412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m   9414\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m   9415\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   9416\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9421\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m   9422\u001B[0m )\n\u001B[0;32m-> 9423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mapply()\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/pandas/core/apply.py:678\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[0;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/pandas/core/apply.py:798\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 798\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_generator()\n\u001B[1;32m    800\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/pandas/core/apply.py:814\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    812\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m--> 814\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf(v)\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m    816\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m    817\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m    818\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/pandas/core/apply.py:133\u001B[0m, in \u001B[0;36mApply.__init__.<locals>.f\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(x):\n\u001B[0;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/lc/lib/python3.11/site-packages/tqdm/std.py:915\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    909\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    910\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[1;32m    911\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[1;32m    912\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[1;32m    913\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[1;32m    914\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 915\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/runtimes/base.py:102\u001B[0m, in \u001B[0;36mLLMRuntime._process_record\u001B[0;34m(self, record, program, extra_fields, outputs)\u001B[0m\n\u001B[1;32m    100\u001B[0m     verified_output \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mstr\u001B[39m(result)}\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 102\u001B[0m     verified_output \u001B[38;5;241m=\u001B[39m {field: result[field] \u001B[38;5;28;01mfor\u001B[39;00m field \u001B[38;5;129;01min\u001B[39;00m outputs}\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m verified_output\n",
      "File \u001B[0;32m~/PycharmProjects/ADALA/adala/runtimes/base.py:102\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    100\u001B[0m     verified_output \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mstr\u001B[39m(result)}\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 102\u001B[0m     verified_output \u001B[38;5;241m=\u001B[39m {field: result[field] \u001B[38;5;28;01mfor\u001B[39;00m field \u001B[38;5;129;01min\u001B[39;00m outputs}\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m verified_output\n",
      "File \u001B[0;32m~/PycharmProjects/guidance/guidance/_program.py:470\u001B[0m, in \u001B[0;36mProgram.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m--> 470\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variables[key]\n",
      "\u001B[0;31mKeyError\u001B[0m: 'predictions'"
     ]
    }
   ],
   "source": [
    "predictions = agent.apply_skills()\n",
    "pd.concat((df, run_results.experience.predictions), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d49385",
   "metadata": {},
   "source": [
    "## Labeling the Data\n",
    "We now have some basic predictions for our data. Now, these predictions could be all correct or wildly incorrect, but we don't know at this point. We need to incorporate an annotation team to provide feedback. Since this is a quickstart, we will apply some labels to the dataframe directly. Let's fix them and create a _ground truth_ that is reliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, 'ground_truth'] = 'Subjective'\n",
    "df.loc[1, 'ground_truth'] = 'Subjective'\n",
    "df.loc[2, 'ground_truth'] = 'Objective'\n",
    "df.loc[3, 'ground_truth'] = 'Objective'\n",
    "df.loc[4, 'ground_truth'] = 'Objective'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f1081",
   "metadata": {},
   "source": [
    "## Improving the Agent\n",
    "Now that we have ground truth labels for our data, we can ask our agent to learn and improve itself by using it as a guide. \n",
    "\n",
    "We can see in the output:\n",
    "- System Prompt - the agent prompt used to improve our labeling skill\n",
    "- User Prompt - the original LLM prompt we created for our skill\n",
    "- Assistant Prompt - our updated prompt learned from our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b28a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn_results = agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00578238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn_results.experience.updated_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e96cb",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c653a8",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "We can incorporate our updated instructions into our agent's skill, and run it on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Output: {{{{gen 'predictions'}}}}\".format(a='aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d021e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}